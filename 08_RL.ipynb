{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 08_RL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lengwe/deep-learning-course/blob/master/08_RL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gPhGQSZ1era"
      },
      "source": [
        "# Deep Reinforcement Learning: An Introduction\n",
        "\n",
        "In this tutorial, we will enter the world of Deep Reinforcement Learning (DRL). In particular, we will first familiarize ourselves with some basic concepts of Reinforcement Learning (RL), then we will implement a classical tabular Q-learning method for the classic [Frozen Lake](https://gym.openai.com/envs/FrozenLake-v0/) puzzle and finally, implement a Deep Q-learning approach for the [CartPole](https://gym.openai.com/envs/CartPole-v1/) problem.\n",
        "\n",
        "\n",
        "> \n",
        "\n",
        "\n",
        "\n",
        "![alt text](https://media2.giphy.com/media/46ib09ZL1SdWuREnj3/giphy.gif?cid=3640f6095c6e92762f3446634d90bc65) ![alt text](https://media0.giphy.com/media/d9QiBcfzg64Io/200w.webp?cid=3640f6095c6e93e92f30655873731752)![alt text](https://i.gifer.com/GpAY.gif)\n",
        "\n",
        "The gifs above, show the results obtained by [Deepmind](https://arxiv.org/pdf/1312.5602v1.pdf) in one of their latest papers. They successfully trained an RL agent using deep Q-learning to play classical Atari arcade games. Let's see now how they did it.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmpPzxlbwvxI"
      },
      "source": [
        "# Q-Learning \n",
        "\n",
        "This family of RL methods try to learn an approximator of the action-value functions $Q(s,a)$  based on the [Bellman equation](https://en.wikipedia.org/wiki/Bellman_equation), such that the update using a classical [gradient descent ](https://en.wikipedia.org/wiki/Gradient_descent) formulation is given by:\n",
        "$$Q\\left(s,a\\right)=Q\\left(s,a\\right)+ \\alpha \\left(r+\\gamma \\max _{a} Q\\left(s_{t+1},a\\right)-Q\\left(s,a\\right)\\right).$$\n",
        "Where $\\alpha$ is the step size. \n",
        " Q-Learning updates the estimated reward at each time step and  uses the old estimate $ \\max _{a}Q\\left(s_{t+1},a\\right)$ to update the new ones. In a more algorithmic way, the Q-Learning process is the following:\n",
        "\n",
        "\n",
        "1.   Initialize Q-values at random $Q\\left(s,a\\right)$.\n",
        "2. Forever or until learning is stopped do:\n",
        "> 1.  Observe state $s$.\n",
        "> 2.   Take action $a$ according to your policy, e.g., $\\epsilon$-greedy.\n",
        "> 3.   Observe reward $r$ and new state $s_{t+1}$.\n",
        "> 4. Based on your actual estimates, compute $\\max _{a}Q\\left(s_{t+1},a\\right)$.\n",
        "> 5. Update your current estimate for  $Q\\left(s,a\\right)$:\n",
        "$$Q\\left(s,a\\right)=Q\\left(s,a\\right)+ \\alpha \\left(r+\\gamma \\max _{a} Q\\left(s_{t+1},a\\right)-Q\\left(s,a\\right)\\right).$$\n",
        "\n",
        "Okay, now that we are familiar with Q-Learning lets jump to a real implementation of it.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_9McSwZh5sT"
      },
      "source": [
        "\n",
        "## Tabular Q-Learning with Frozen Lake\n",
        "In this section we will teach an agent how to play  the [Frozen lake](https://gym.openai.com/envs/FrozenLake-v0/) game using a classical tabular Q-learning. Brace yourselves, winter is coming! \n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/simoninithomas/Deep_reinforcement_learning_Course/1ee37cfc3130057f828f19b3cee6066d41c1eeb4/Q%20learning/FrozenLake/frozenlake.png)\n",
        "\n",
        "Winter has arrived and you and your friends were tossing around a frisbee at the park when you made a wild throw that left the frisbee out in the middle of the lake. The water is mostly frozen, but there are a few holes where the ice has melted. If you step into one of those holes, you'll fall into the freezing water. At this time, there's an international frisbee shortage, so you must navigate across the lake and retrieve the disc. However, the ice is slippery, so you won't always move in the direction you intend.\n",
        "The goal of this game is to go from the starting state (S) to the goal state (G) by walking only on frozen tiles (F) and avoid holes (H). However, the ice is slippery (!!), so you won't always move in the direction you intend (stochastic environment), i.e., there is a probability $p$ that you move in the direction selected and a probability $(1-p)$ that given the slippery ice, you move to a random position near position. Specifically, let's say you select the action UP, you have a probability of 1/3 of actually going UP, 1/3 of going RIGHT and 1/3 of going LEFT. Similarly, if you select LEFT, you have a probability of 1/3 of actually going LEFT, 1/3 of going UP and 1/3 of going DOWN.\n",
        "\n",
        "The lake is represented by a 4x4 grid and the location where the frisbee has landed (G) as well as the holes (H) is always the same for every new game. The game is restarted every time you have successfully recovered the frisbee or you have fallen into the cold waters. A reward of +1 is given every time you recover the frisbee and 0 other way.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNrutC72jZRZ"
      },
      "source": [
        "**Step 0: Import the needed libraries:**\n",
        "\n",
        "We will be using 3 libraries:\n",
        "\n",
        "* Numpy for our Qtable.\n",
        "* OpenAI Gym for our FrozenLake Environment\n",
        "* Random to generate random numbers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0OxrnpgjyFh"
      },
      "source": [
        "from IPython.display import HTML\n",
        "import numpy as np\n",
        "import gym\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-Nx8PYnj4I5"
      },
      "source": [
        "**Environment creation:**\n",
        "\n",
        "OpenAi is  a library composed of many environments that we can use to train our agents, in our case we choose to use the Frozen Lake."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWgurerLkNLe"
      },
      "source": [
        "env = gym.make(\"FrozenLake-v0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeaPjILgkS7Z"
      },
      "source": [
        "**Q-table**\n",
        "\n",
        " Now, we'll create our Q-table. The goal of the Q-table is to store the estimates $Q\\left(s,a\\right)$ and retrieve them when necessary. In this game the states are represented by each of the 16 grid positions being 0 the starting position and 16 the goal position and the actions are 4: left, right, up and down. Our Q-table will have then $16 \\times 4$ positions, where the value of the first column of the first row represents the expected return of being in position 0 and taking left.\n",
        " \n",
        "The number of rows (states) and columns (actions) the table will have can also be obtained using the values action_size and the state_size from the OpenAI Gym library: *env.action_space.n* and* env.observation_space.n*.\n",
        " \n",
        "We initialize the table to 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eintO6cYk5qN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46f3184f-d59d-45b4-ef21-4ad98185ea4a"
      },
      "source": [
        "action_size = env.action_space.n\n",
        "state_size = env.observation_space.n\n",
        "qtable = np.zeros((state_size, action_size))\n",
        "print(qtable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G06GlU14k_JG"
      },
      "source": [
        "**Hyperparameters**\n",
        "\n",
        "Following, we specify the hyperparameters:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYWdb_rHlFzq"
      },
      "source": [
        "total_episodes = 25000        # Total episodes\n",
        "learning_rate = 0.8           # Learning rate (alpha in the previous formulation)\n",
        "max_steps = 99                # Max steps per episode\n",
        "gamma = 0.95                  # Discounting rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVb-8n8Jlkhs"
      },
      "source": [
        "At first, we don't know how to interact with the environment (Q-table values set to 0), so we start exploring it by taking a random action with probability $\\epsilon=1$, capturing the rewards obtained and updating the Q-values of the table accordingly. As time passes by, we start knowing more and more the environment, so we reduce (decay_rate) the probability of taking a random action and we start exploiting our knowledge, we choose the action that leads us to the highest reward, i.e., the one with the highest Q-value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXq90uCMllKE"
      },
      "source": [
        "# Exploration parameters\n",
        "epsilon = 1.0                 # Exploration rate\n",
        "max_epsilon = 1.0             # Exploration probability at start\n",
        "min_epsilon = 0.01            # Minimum exploration probability \n",
        "decay_rate = 0.005             # Exponential decay rate for exploration prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVu4B3F2lLl8"
      },
      "source": [
        "**Q-Learning**\n",
        "\n",
        "Now we implement the Q-Learning algorithm: \n",
        "> 1.  Observe state $s$.\n",
        "> 2.   Choose a random value $v$ between 0 and 1.\n",
        "> 3. If $v<\\epsilon$, we choose a random action, otherwise we select the action with maximum $Q(s,a)$.\n",
        "> 3.   Observe reward $r$ and new state $s_{t+1}$.\n",
        "> 4. Based on your previous estimates, compute $\\max _{a}Q\\left(s_{t+1},a\\right)$.\n",
        "> 5. Update your current estimates for  $Q\\left(s,a\\right)$:\n",
        "$$Q\\left(s,a\\right)=Q\\left(s,a\\right)+ \\alpha \\left(r+\\gamma \\max _{a} Q\\left(s_{t+1},a\\right)-Q\\left(s,a\\right)\\right).$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYbqMpg-liRd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f536434f-059f-4d40-9dca-18eaef359d06"
      },
      "source": [
        "# List of rewards\n",
        "rewards = []\n",
        "\n",
        "for episode in range(total_episodes):\n",
        "    # Reset the environment\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "    total_rewards = 0\n",
        "    \n",
        "    for step in range(max_steps):\n",
        "        # 3. Choose an action a in the current world state (s)\n",
        "        ## First we randomize a number\n",
        "        exp_exp_tradeoff = random.uniform(0, 1)\n",
        "        \n",
        "        ## If this number > greater than epsilon --> exploitation (taking the biggest Q value for this state)\n",
        "        if exp_exp_tradeoff > epsilon:\n",
        "            action = np.argmax(qtable[state,:])\n",
        "\n",
        "        # Else doing a random choice --> exploration\n",
        "        else:\n",
        "            action = env.action_space.sample()\n",
        "\n",
        "        # Take the action (a) and observe the outcome state(s') and reward (r)\n",
        "        new_state, reward, done, info = env.step(action)\n",
        "\n",
        "        # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
        "        # qtable[new_state,:] : all the actions we can take from new state\n",
        "        qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * np.max(qtable[new_state, :]) - qtable[state, action])\n",
        "        \n",
        "        total_rewards += reward\n",
        "        \n",
        "        # Our new state is state\n",
        "        state = new_state\n",
        "        \n",
        "        # If done (if we're dead) : finish episode\n",
        "        if done == True: \n",
        "            break\n",
        "        \n",
        "    # Reduce epsilon (because we need less and less exploration)\n",
        "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode) \n",
        "    rewards.append(total_rewards)\n",
        "\n",
        "print (\"Score over time: \" +  str(sum(rewards)/total_episodes))\n",
        "print(qtable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score over time: 0.48812\n",
            "[[6.79933410e-02 1.76044082e-01 6.65461802e-02 5.84886212e-02]\n",
            " [7.44919075e-03 2.10025202e-03 6.76944151e-03 1.02290711e-01]\n",
            " [6.06414294e-03 1.56393306e-02 9.13088662e-03 4.84506054e-02]\n",
            " [1.04692670e-03 2.67163429e-04 1.18604169e-03 1.95855418e-02]\n",
            " [2.00750619e-01 1.44812071e-01 4.00351445e-02 3.92186987e-02]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.36774882e-06 8.92752239e-05 6.83020859e-02 9.71495025e-05]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [9.55176983e-03 4.40863321e-03 8.95995137e-02 3.73455057e-01]\n",
            " [2.26837341e-02 4.18069768e-01 2.30815525e-02 3.31758650e-01]\n",
            " [6.63846778e-01 6.44478636e-04 3.28702947e-03 4.68239268e-03]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [8.19416230e-02 2.03033362e-02 4.28264673e-01 1.63153181e-01]\n",
            " [1.93559601e-01 7.91512409e-01 7.27530419e-01 6.51312551e-01]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvcHhVx5lrWZ"
      },
      "source": [
        "**Use our Q-table to play FrozenLake!**\n",
        "\n",
        "After 25000 episodes, our Q-table can be used as a \"cheatsheet\" to play FrozenLake\"!\n",
        "  \n",
        "By running this cell, you can see our agent playing FrozenLake:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz65tCGSlzSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "621709c7-7ca0-4aed-c978-d80c739ae687"
      },
      "source": [
        "env.reset()\n",
        "\n",
        "state = env.reset()\n",
        "step = 0\n",
        "done = False\n",
        "print(\"****************************************************\")\n",
        "env.render()\n",
        "for step in range(max_steps):\n",
        "\n",
        "    # Take the action (index) that have the maximum expected future reward given that state\n",
        "    action = np.argmax(qtable[state,:])\n",
        "\n",
        "    new_state, reward, done, info = env.step(action)\n",
        "\n",
        "    env.render()\n",
        "\n",
        "    # We print the current step.\n",
        "    print(\"Number of steps\", step)\n",
        "    if done:\n",
        "      break\n",
        "    state = new_state\n",
        "env.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "****************************************************\n",
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Down)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 0\n",
            "  (Down)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 1\n",
            "  (Up)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 2\n",
            "  (Up)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 3\n",
            "  (Down)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 4\n",
            "  (Down)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 5\n",
            "  (Left)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "Number of steps 6\n",
            "  (Up)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 7\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 8\n",
            "  (Down)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 9\n",
            "  (Down)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 10\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 11\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 12\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 13\n",
            "  (Up)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 14\n",
            "  (Up)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 15\n",
            "  (Down)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 16\n",
            "  (Down)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 17\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 18\n",
            "  (Down)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 19\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 20\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 21\n",
            "  (Down)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 22\n",
            "  (Down)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 23\n",
            "  (Down)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 24\n",
            "  (Up)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 25\n",
            "  (Down)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 26\n",
            "  (Left)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "Number of steps 27\n",
            "  (Up)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 28\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 29\n",
            "  (Down)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 30\n",
            "  (Down)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 31\n",
            "  (Up)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 32\n",
            "  (Down)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 33\n",
            "  (Down)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 34\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 35\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 36\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 37\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 38\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 39\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 40\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 41\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 42\n",
            "  (Up)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 43\n",
            "  (Up)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 44\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 45\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 46\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 47\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 48\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 49\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 50\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 51\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 52\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 53\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 54\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 55\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 56\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 57\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 58\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 59\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 60\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 61\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 62\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 63\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 64\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 65\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 66\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 67\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 68\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 69\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 70\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 71\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 72\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 73\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 74\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 75\n",
            "  (Up)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 76\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 77\n",
            "  (Up)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 78\n",
            "  (Up)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 79\n",
            "  (Down)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 80\n",
            "  (Left)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "Number of steps 81\n",
            "  (Up)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "Number of steps 82\n",
            "  (Up)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "Number of steps 83\n",
            "  (Up)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "Number of steps 84\n",
            "  (Up)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 85\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 86\n",
            "  (Down)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 87\n",
            "  (Up)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 88\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 89\n",
            "  (Up)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 90\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 91\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 92\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 93\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 94\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 95\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 96\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 97\n",
            "  (Up)\n",
            "SFF\u001b[41mF\u001b[0m\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSroWmlroYiC"
      },
      "source": [
        "Let’s see how many times our agent finds the frisbee 🎉\n",
        "\n",
        "To this end we will print the last step of the game."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3BUEqOzocSl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fea06cb-91fd-435d-a792-d30af08e3089"
      },
      "source": [
        "games=5\n",
        "step = 0\n",
        "done = False\n",
        "print(\"****************************************************\")\n",
        "for game in range(games):\n",
        "  env.reset()\n",
        "  state = env.reset()\n",
        "  for step in range(max_steps):\n",
        "\n",
        "      # Take the action (index) that have the maximum expected future reward given that state\n",
        "      action = np.argmax(qtable[state,:])\n",
        "\n",
        "      new_state, reward, done, info = env.step(action)\n",
        "\n",
        "      if done:\n",
        "        # Here, we decide to only print the last state (to see if our agent is on the goal or fall into a hole)\n",
        "        env.render()\n",
        "  \n",
        "        # We print the number of step it took.\n",
        "        print(\"Number of steps\", step)\n",
        "        done= False\n",
        "        break\n",
        "      state = new_state\n",
        "  env.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "****************************************************\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "Number of steps 12\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "Number of steps 22\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "Number of steps 67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfLNsIPtQevL",
        "outputId": "344ea456-68aa-4236-e8b2-e0c7b3e7ca3d"
      },
      "source": [
        "games=10000\n",
        "step = 0\n",
        "total_rewards = 0\n",
        "done = False\n",
        "for game in range(games):\n",
        "  env.reset()\n",
        "  state = env.reset()\n",
        "  for step in range(max_steps):\n",
        "\n",
        "      # Take the action (index) that have the maximum expected future reward given that state\n",
        "      action = np.argmax(qtable[state,:])\n",
        "\n",
        "      new_state, reward, done, info = env.step(action)\n",
        "\n",
        "      if done:\n",
        "        total_rewards += reward\n",
        "        done= False\n",
        "        break\n",
        "      state = new_state\n",
        "  env.close()\n",
        "success = total_rewards / games\n",
        "print(\"Ratio of sucessfully finished episodes is {:f}\".format(success))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ratio of sucessfully finished episodes is 0.542400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d3L77JNpUvy"
      },
      "source": [
        "## CartPole\n",
        "\n",
        "That wasn't so hard! How about trying to balance a pole so it does not fall? In this section we will address the [CartPole](https://gym.openai.com/envs/CartPole-v1/) problem, let's get to it!\n",
        "\n",
        "![texto alternativo](https://keon.github.io/images/deep-q-learning/animation.gif)\n",
        "\n",
        "As before we will use Q-learning to train our agent, so let's start by constructing our Q-table. We first need to find out the number of columns and rows of it. By checking the environment specifications of [OpenAi](https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py), we see that the actions are left and right, so we need two columns for the actions. On the other hand, the state information is given by:\n",
        "\n",
        "        Num\tObservation                 Min         Max\n",
        "        0\tCart Position             -4.8            4.8\n",
        "        1\tCart Velocity             -Inf            Inf\n",
        "        2\tPole Angle                 -24 deg        24 deg\n",
        "        3\tPole Velocity At Tip      -Inf            Inf\n",
        "      \n",
        "The cart position goes from -4.8 to 4.8 with a resolution of 0.01, which means $\\frac{4.8 \\times 2}{0.01}=960$ possible carts positions, while the cart velocity goes from $-\\infty$ to $\\infty$!. How we are going to construct a table with $\\infty$ rows?\n",
        " \n",
        "Do not panic! That is when deep learning steps up and takes over the stage. As you have already seen the use of Deep Neural Networks as general function approximators have been proven to work very well in a wide range of areas, reinforcement learning is not an exception. In this case we will use the NNs as function approximation between the mapping of states to actions, so for every input state, we want the NNs to output an approximation of the $Q\\left(s,a\\right)$.\n",
        "\n",
        "![alt text](https://proxy.duckduckgo.com/iu/?u=https%3A%2F%2Fcdn-images-1.medium.com%2Fmax%2F1318%2F1*Gh5PS4R_A5drl5ebd_gNrg%402x.png&f=1)\n",
        "\n",
        "In this particular scenario, the input layer will have the same number of inputs as environment parameters, 4, and the output layer will have the same number of outputs as actions, in this case 2. \n",
        "\n",
        "**Reward:** A reward of +1 is provided for every timestep that the pole remains upright. The episode ends when the pole is more than 15 degrees from vertical.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHi3LRul2b6h"
      },
      "source": [
        "\n",
        "**Step 0: Import the needed libraries**\n",
        "\n",
        "We start by importing the needed libraries:\n",
        "We will be using 3 libraries:\n",
        "* Keras: for our DNNs.\n",
        "* OpenAI Gym: for our CartPole Environment\n",
        "* Random: to generate random numbers.\n",
        "* Collections: Collection will be use to create a memory buffer to store the tuples $\\left(S_t, A_t, R_t,S_{t+1}\\right)$ of transactions. \n",
        "\n",
        "The idea behind the use of a memory buffer is that most optimization algorithms, including gradient descent, assume that the samples used in an update step are independent and identically distributed. Clearly in the defined environment that is not the case, however, by sampling uniformly the memory buffer with a high number of samples the correlation between contiguous samples is broken and less likely to be correlated samples are used to update the network's weights, leading to a stable optimization of the action-parameter selection.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO4Qbc942zPJ"
      },
      "source": [
        "import random\n",
        "import gym\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KDyanK23SQH"
      },
      "source": [
        "**The Agent**\n",
        "\n",
        "Let's start by coding a general DQ-Learning agent. The state and action size are passed as parameters and we configure a replay buffer to have capacity to store 2000 experienced transitions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18b_7T9K-V_a"
      },
      "source": [
        " class DQNAgent:\n",
        "    def __init__(self, state_size, action_size):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.memory = deque(maxlen=2000)\n",
        "        self.gamma = 0.95    # discount rate\n",
        "        self.epsilon = 1.0  # exploration rate\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.learning_rate = 0.001\n",
        "        self.model = self._build_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xws00CC6Ae7K"
      },
      "source": [
        "Now we address the DNNs; we are going to use two fully connected layers of 24 neurons each and as an optimizer we select Adam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUxh0JOWAtPT"
      },
      "source": [
        "    def _build_model(self):\n",
        "        # Neural Net for Deep-Q learning Model\n",
        "        model = Sequential()\n",
        "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
        "        model.add(Dense(24, activation='relu'))\n",
        "        model.add(Dense(self.action_size, activation='linear'))\n",
        "        model.compile(loss='mse',\n",
        "                      optimizer=Adam(lr=self.learning_rate))\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yA4DQkqcBQ84"
      },
      "source": [
        "Now define the method to store the transitions into the memory buffer.\n",
        "The parameter done is a boolean returned true when the pole has fallen. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qv7a_raBQGr"
      },
      "source": [
        "    def remember(self, state, action, reward, next_state, done):\n",
        "          self.memory.append((state, action, reward, next_state, done))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9X-HisYBc9m"
      },
      "source": [
        "Again, we implement and $\\epsilon$-greedy policy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXJoxwi2Bmss"
      },
      "source": [
        "     def act(self, state):\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "                return random.randrange(self.action_size)\n",
        "            act_values = self.model.predict(state)\n",
        "            return np.argmax(act_values[0]) # returns action"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bmi6bk5Bv7E"
      },
      "source": [
        "Then comes the implementation of the Q-Learning method:\n",
        "\n",
        "\n",
        "\n",
        "1.   We obtain the samples to train the DNN from the replay buffer.\n",
        "2.  We compute $target=r+\\gamma \\max _{a} Q\\left(s_{t+1},a\\right)$, by doing a forward pass using next_state value.\n",
        "3. We do a forward pass through the network to obtain the $Q\\left(s,a\\right)$ for all the possible actions.\n",
        "4. In order to just update the parameter of the action taken, we copy target to the value of the $Q\\left(s,a\\right)$ of the actual $a$ taken.\n",
        "5. We update the parameters of the network using MSE as loss function.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYgDWxUmBu8n"
      },
      "source": [
        "def replay(self, batch_size):\n",
        "    minibatch = random.sample(self.memory, batch_size)\n",
        "    ### This code below generates batches of states, actions, rewards\n",
        "    ### next states out of the sampled minibatch\n",
        "    state_b = np.squeeze(np.array(list(map(lambda x: x[0], minibatch))))\n",
        "    action_b = np.squeeze(np.array(list(map(lambda x: x[1], minibatch))))\n",
        "    reward_b = np.squeeze(np.array(list(map(lambda x: x[2], minibatch))))\n",
        "    next_state_b = np.squeeze(np.array(list(map(lambda x: x[3], minibatch))))\n",
        "    done_b = np.squeeze(np.array(list(map(lambda x: x[4], minibatch))))\n",
        "  \n",
        "    target = (reward_b + self.gamma *\n",
        "                      np.amax(self.model.predict(next_state_b), 1))\n",
        "    target[done_b==1] = reward_b[done_b==1]\n",
        "    target_f = self.model.predict(state_b)\n",
        "    for k in range(target_f.shape[0]):\n",
        "      target_f[k][action_b[k]] = target[k]\n",
        "    self.model.train_on_batch(state_b, target_f)\n",
        "    if self.epsilon > self.epsilon_min:\n",
        "        self.epsilon *= self.epsilon_decay\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2E-OJlAFraT"
      },
      "source": [
        "Now we define the operations to load and save the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeE1SshPFqrn"
      },
      "source": [
        "def load(self, name):\n",
        "  self.model.load_weights(name)\n",
        "def save(self, name):\n",
        "  self.model.save_weights(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4J6L3xbF10Y"
      },
      "source": [
        "Colab does not recognize all the previous code parts defined under the same class, to this end we run everything this time altogether. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFSDV2qAFYRk"
      },
      "source": [
        "class DQNAgent:\n",
        "  def __init__(self, state_size, action_size):\n",
        "    self.state_size = state_size\n",
        "    self.action_size = action_size\n",
        "    self.memory = deque(maxlen=20000)\n",
        "    self.gamma = 0.95    # discount rate\n",
        "    self.epsilon = 1.0  # exploration rate\n",
        "    self.epsilon_min = 0.01\n",
        "    self.epsilon_decay = 0.995\n",
        "    self.learning_rate = 0.001\n",
        "    self.model = self._build_model()\n",
        "\n",
        "  def _build_model(self):\n",
        "    # Neural Net for Deep-Q learning Model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
        "    model.add(Dense(48, activation='relu'))\n",
        "    model.add(Dense(self.action_size, activation='linear'))\n",
        "    model.compile(loss='mse',\n",
        "                  optimizer=Adam(lr=self.learning_rate))\n",
        "    return model\n",
        "\n",
        "  def remember(self, state, action, reward, next_state, done):\n",
        "    self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "  def act(self, state):# We implement the epsilon-greedy policy\n",
        "    if np.random.rand() <= self.epsilon:\n",
        "        return random.randrange(self.action_size)\n",
        "    act_values = self.model.predict(state)\n",
        "    return np.argmax(act_values[0]) # returns action\n",
        "  \n",
        "  def exploit(self, state): # When we test the agent we dont want it to explore anymore, but to exploit what it has learnt\n",
        "    act_values = self.model.predict(state)\n",
        "    return np.argmax(act_values[0]) \n",
        "\n",
        "  def replay(self, batch_size):\n",
        "    minibatch = random.sample(self.memory, batch_size)\n",
        "    \n",
        "    state_b = np.squeeze(np.array(list(map(lambda x: x[0], minibatch))))\n",
        "    action_b = np.squeeze(np.array(list(map(lambda x: x[1], minibatch))))\n",
        "    reward_b = np.squeeze(np.array(list(map(lambda x: x[2], minibatch))))\n",
        "    next_state_b = np.squeeze(np.array(list(map(lambda x: x[3], minibatch))))\n",
        "    done_b = np.squeeze(np.array(list(map(lambda x: x[4], minibatch))))\n",
        "    target = (reward_b + self.gamma *\n",
        "                      np.amax(self.model.predict(next_state_b), 1))\n",
        "    target[done_b==1] = reward_b[done_b==1]\n",
        "    target_f = self.model.predict(state_b)\n",
        "    for k in range(target_f.shape[0]):\n",
        "      target_f[k][action_b[k]] = target[k]\n",
        "    self.model.train_on_batch(state_b, target_f)\n",
        "    if self.epsilon > self.epsilon_min:\n",
        "        self.epsilon *= self.epsilon_decay\n",
        "  def load(self, name):\n",
        "    self.model.load_weights(name)\n",
        "  def save(self, name):\n",
        "    self.model.save_weights(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6YDZhTIDjiC"
      },
      "source": [
        "**Main**\n",
        "\n",
        "Following we implement the training of the agent. (Warning: it takes a while)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwA2WXrnDpzV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0accae1-3c38-47b9-c90f-b594f59fe5ca"
      },
      "source": [
        "EPISODES = 200\n",
        "env = gym.make('CartPole-v0')\n",
        "state_size = env.observation_space.shape[0]\n",
        "action_size = env.action_space.n\n",
        "agent = DQNAgent(state_size, action_size)\n",
        "done = False\n",
        "batch_size = 32\n",
        "\n",
        "for e in range(EPISODES):\n",
        "    state = env.reset()\n",
        "    state = np.reshape(state, [1, state_size])\n",
        "    for time in range(200):\n",
        "        action = agent.act(state)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        next_state = np.reshape(next_state, [1, state_size])\n",
        "        agent.remember(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "        if done:\n",
        "            print(\"episode: {}/{}, score: {}, e: {:.2}\"\n",
        "                  .format(e, EPISODES, time, agent.epsilon))\n",
        "            break\n",
        "        if len(agent.memory) > batch_size:\n",
        "            agent.replay(batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "episode: 0/200, score: 15, e: 1.0\n",
            "episode: 1/200, score: 11, e: 1.0\n",
            "episode: 2/200, score: 11, e: 0.97\n",
            "episode: 3/200, score: 13, e: 0.9\n",
            "episode: 4/200, score: 20, e: 0.82\n",
            "episode: 5/200, score: 12, e: 0.77\n",
            "episode: 6/200, score: 11, e: 0.73\n",
            "episode: 7/200, score: 10, e: 0.69\n",
            "episode: 8/200, score: 11, e: 0.66\n",
            "episode: 9/200, score: 17, e: 0.6\n",
            "episode: 10/200, score: 10, e: 0.57\n",
            "episode: 11/200, score: 10, e: 0.55\n",
            "episode: 12/200, score: 21, e: 0.49\n",
            "episode: 13/200, score: 10, e: 0.47\n",
            "episode: 14/200, score: 14, e: 0.44\n",
            "episode: 15/200, score: 9, e: 0.42\n",
            "episode: 16/200, score: 11, e: 0.39\n",
            "episode: 17/200, score: 10, e: 0.37\n",
            "episode: 18/200, score: 11, e: 0.35\n",
            "episode: 19/200, score: 11, e: 0.34\n",
            "episode: 20/200, score: 8, e: 0.32\n",
            "episode: 21/200, score: 9, e: 0.31\n",
            "episode: 22/200, score: 9, e: 0.29\n",
            "episode: 23/200, score: 10, e: 0.28\n",
            "episode: 24/200, score: 10, e: 0.27\n",
            "episode: 25/200, score: 13, e: 0.25\n",
            "episode: 26/200, score: 8, e: 0.24\n",
            "episode: 27/200, score: 9, e: 0.23\n",
            "episode: 28/200, score: 8, e: 0.22\n",
            "episode: 29/200, score: 8, e: 0.21\n",
            "episode: 30/200, score: 8, e: 0.2\n",
            "episode: 31/200, score: 11, e: 0.19\n",
            "episode: 32/200, score: 10, e: 0.18\n",
            "episode: 33/200, score: 8, e: 0.18\n",
            "episode: 34/200, score: 14, e: 0.16\n",
            "episode: 35/200, score: 8, e: 0.16\n",
            "episode: 36/200, score: 10, e: 0.15\n",
            "episode: 37/200, score: 9, e: 0.14\n",
            "episode: 38/200, score: 10, e: 0.14\n",
            "episode: 39/200, score: 9, e: 0.13\n",
            "episode: 40/200, score: 11, e: 0.12\n",
            "episode: 41/200, score: 9, e: 0.12\n",
            "episode: 42/200, score: 11, e: 0.11\n",
            "episode: 43/200, score: 10, e: 0.11\n",
            "episode: 44/200, score: 9, e: 0.1\n",
            "episode: 45/200, score: 9, e: 0.097\n",
            "episode: 46/200, score: 10, e: 0.092\n",
            "episode: 47/200, score: 9, e: 0.088\n",
            "episode: 48/200, score: 10, e: 0.084\n",
            "episode: 49/200, score: 14, e: 0.078\n",
            "episode: 50/200, score: 10, e: 0.074\n",
            "episode: 51/200, score: 14, e: 0.069\n",
            "episode: 52/200, score: 17, e: 0.063\n",
            "episode: 53/200, score: 21, e: 0.057\n",
            "episode: 54/200, score: 13, e: 0.054\n",
            "episode: 55/200, score: 12, e: 0.05\n",
            "episode: 56/200, score: 14, e: 0.047\n",
            "episode: 57/200, score: 21, e: 0.042\n",
            "episode: 58/200, score: 14, e: 0.039\n",
            "episode: 59/200, score: 17, e: 0.036\n",
            "episode: 60/200, score: 15, e: 0.034\n",
            "episode: 61/200, score: 20, e: 0.03\n",
            "episode: 62/200, score: 17, e: 0.028\n",
            "episode: 63/200, score: 13, e: 0.026\n",
            "episode: 64/200, score: 27, e: 0.023\n",
            "episode: 65/200, score: 18, e: 0.021\n",
            "episode: 66/200, score: 67, e: 0.015\n",
            "episode: 67/200, score: 18, e: 0.014\n",
            "episode: 68/200, score: 17, e: 0.013\n",
            "episode: 69/200, score: 23, e: 0.011\n",
            "episode: 70/200, score: 17, e: 0.01\n",
            "episode: 71/200, score: 81, e: 0.01\n",
            "episode: 72/200, score: 18, e: 0.01\n",
            "episode: 73/200, score: 62, e: 0.01\n",
            "episode: 74/200, score: 39, e: 0.01\n",
            "episode: 75/200, score: 14, e: 0.01\n",
            "episode: 76/200, score: 27, e: 0.01\n",
            "episode: 77/200, score: 29, e: 0.01\n",
            "episode: 78/200, score: 35, e: 0.01\n",
            "episode: 79/200, score: 26, e: 0.01\n",
            "episode: 80/200, score: 59, e: 0.01\n",
            "episode: 81/200, score: 38, e: 0.01\n",
            "episode: 82/200, score: 55, e: 0.01\n",
            "episode: 83/200, score: 35, e: 0.01\n",
            "episode: 84/200, score: 54, e: 0.01\n",
            "episode: 85/200, score: 83, e: 0.01\n",
            "episode: 86/200, score: 57, e: 0.01\n",
            "episode: 87/200, score: 66, e: 0.01\n",
            "episode: 88/200, score: 66, e: 0.01\n",
            "episode: 89/200, score: 92, e: 0.01\n",
            "episode: 90/200, score: 79, e: 0.01\n",
            "episode: 91/200, score: 150, e: 0.01\n",
            "episode: 92/200, score: 84, e: 0.01\n",
            "episode: 93/200, score: 66, e: 0.01\n",
            "episode: 94/200, score: 72, e: 0.01\n",
            "episode: 95/200, score: 100, e: 0.01\n",
            "episode: 96/200, score: 101, e: 0.01\n",
            "episode: 97/200, score: 171, e: 0.01\n",
            "episode: 98/200, score: 167, e: 0.01\n",
            "episode: 99/200, score: 101, e: 0.01\n",
            "episode: 100/200, score: 121, e: 0.01\n",
            "episode: 101/200, score: 177, e: 0.01\n",
            "episode: 102/200, score: 199, e: 0.01\n",
            "episode: 103/200, score: 176, e: 0.01\n",
            "episode: 104/200, score: 151, e: 0.01\n",
            "episode: 105/200, score: 199, e: 0.01\n",
            "episode: 106/200, score: 199, e: 0.01\n",
            "episode: 107/200, score: 199, e: 0.01\n",
            "episode: 108/200, score: 199, e: 0.01\n",
            "episode: 109/200, score: 199, e: 0.01\n",
            "episode: 110/200, score: 199, e: 0.01\n",
            "episode: 111/200, score: 199, e: 0.01\n",
            "episode: 112/200, score: 199, e: 0.01\n",
            "episode: 113/200, score: 199, e: 0.01\n",
            "episode: 114/200, score: 199, e: 0.01\n",
            "episode: 115/200, score: 199, e: 0.01\n",
            "episode: 116/200, score: 199, e: 0.01\n",
            "episode: 117/200, score: 199, e: 0.01\n",
            "episode: 118/200, score: 199, e: 0.01\n",
            "episode: 119/200, score: 199, e: 0.01\n",
            "episode: 120/200, score: 199, e: 0.01\n",
            "episode: 121/200, score: 199, e: 0.01\n",
            "episode: 122/200, score: 199, e: 0.01\n",
            "episode: 123/200, score: 199, e: 0.01\n",
            "episode: 124/200, score: 199, e: 0.01\n",
            "episode: 125/200, score: 199, e: 0.01\n",
            "episode: 126/200, score: 199, e: 0.01\n",
            "episode: 127/200, score: 199, e: 0.01\n",
            "episode: 128/200, score: 199, e: 0.01\n",
            "episode: 129/200, score: 199, e: 0.01\n",
            "episode: 130/200, score: 199, e: 0.01\n",
            "episode: 131/200, score: 199, e: 0.01\n",
            "episode: 132/200, score: 199, e: 0.01\n",
            "episode: 133/200, score: 199, e: 0.01\n",
            "episode: 134/200, score: 199, e: 0.01\n",
            "episode: 135/200, score: 199, e: 0.01\n",
            "episode: 136/200, score: 199, e: 0.01\n",
            "episode: 137/200, score: 199, e: 0.01\n",
            "episode: 138/200, score: 199, e: 0.01\n",
            "episode: 139/200, score: 199, e: 0.01\n",
            "episode: 140/200, score: 199, e: 0.01\n",
            "episode: 141/200, score: 199, e: 0.01\n",
            "episode: 142/200, score: 199, e: 0.01\n",
            "episode: 143/200, score: 199, e: 0.01\n",
            "episode: 144/200, score: 199, e: 0.01\n",
            "episode: 145/200, score: 199, e: 0.01\n",
            "episode: 146/200, score: 199, e: 0.01\n",
            "episode: 147/200, score: 199, e: 0.01\n",
            "episode: 148/200, score: 194, e: 0.01\n",
            "episode: 149/200, score: 199, e: 0.01\n",
            "episode: 150/200, score: 199, e: 0.01\n",
            "episode: 151/200, score: 199, e: 0.01\n",
            "episode: 152/200, score: 199, e: 0.01\n",
            "episode: 153/200, score: 199, e: 0.01\n",
            "episode: 154/200, score: 199, e: 0.01\n",
            "episode: 155/200, score: 199, e: 0.01\n",
            "episode: 156/200, score: 199, e: 0.01\n",
            "episode: 157/200, score: 199, e: 0.01\n",
            "episode: 158/200, score: 199, e: 0.01\n",
            "episode: 159/200, score: 199, e: 0.01\n",
            "episode: 160/200, score: 199, e: 0.01\n",
            "episode: 161/200, score: 199, e: 0.01\n",
            "episode: 162/200, score: 199, e: 0.01\n",
            "episode: 163/200, score: 199, e: 0.01\n",
            "episode: 164/200, score: 199, e: 0.01\n",
            "episode: 165/200, score: 199, e: 0.01\n",
            "episode: 166/200, score: 199, e: 0.01\n",
            "episode: 167/200, score: 199, e: 0.01\n",
            "episode: 168/200, score: 199, e: 0.01\n",
            "episode: 169/200, score: 199, e: 0.01\n",
            "episode: 170/200, score: 199, e: 0.01\n",
            "episode: 171/200, score: 199, e: 0.01\n",
            "episode: 172/200, score: 199, e: 0.01\n",
            "episode: 173/200, score: 199, e: 0.01\n",
            "episode: 174/200, score: 199, e: 0.01\n",
            "episode: 175/200, score: 199, e: 0.01\n",
            "episode: 176/200, score: 199, e: 0.01\n",
            "episode: 177/200, score: 199, e: 0.01\n",
            "episode: 178/200, score: 199, e: 0.01\n",
            "episode: 179/200, score: 199, e: 0.01\n",
            "episode: 180/200, score: 199, e: 0.01\n",
            "episode: 181/200, score: 199, e: 0.01\n",
            "episode: 182/200, score: 199, e: 0.01\n",
            "episode: 183/200, score: 199, e: 0.01\n",
            "episode: 184/200, score: 199, e: 0.01\n",
            "episode: 185/200, score: 199, e: 0.01\n",
            "episode: 186/200, score: 199, e: 0.01\n",
            "episode: 187/200, score: 199, e: 0.01\n",
            "episode: 188/200, score: 199, e: 0.01\n",
            "episode: 189/200, score: 199, e: 0.01\n",
            "episode: 190/200, score: 199, e: 0.01\n",
            "episode: 191/200, score: 199, e: 0.01\n",
            "episode: 192/200, score: 199, e: 0.01\n",
            "episode: 193/200, score: 199, e: 0.01\n",
            "episode: 194/200, score: 199, e: 0.01\n",
            "episode: 195/200, score: 199, e: 0.01\n",
            "episode: 196/200, score: 199, e: 0.01\n",
            "episode: 197/200, score: 199, e: 0.01\n",
            "episode: 198/200, score: 199, e: 0.01\n",
            "episode: 199/200, score: 199, e: 0.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CZXl1U4gwpd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2TqM_HhGVM6"
      },
      "source": [
        "Let's now visualize how the agent is performing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGglc_BfYam-"
      },
      "source": [
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMUl6WrhYtuj"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()\n",
        "from gym.wrappers import Monitor\n",
        "import glob\n",
        "import io\n",
        "import base64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WO20MXmfNs4E"
      },
      "source": [
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment and displaying it\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKv6DNBDGY0N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "fa6fc20b-0917-4cb1-ca54-b9e04d0d7778"
      },
      "source": [
        "from IPython.display import HTML\n",
        "env = wrap_env(gym.make('CartPole-v1'))\n",
        "state_size = env.observation_space.shape[0]\n",
        "action_size = env.action_space.n\n",
        "done = False\n",
        "state = env.reset()\n",
        "state = np.reshape(state, [1, state_size])\n",
        "for time in range(200):\n",
        "    screen = env.render()\n",
        "    action = agent.exploit(state)\n",
        "    state, reward, done, _ = env.step(action)\n",
        "    if done:\n",
        "      break\n",
        "    state = np.reshape(state, [1, state_size])\n",
        "\n",
        "env.close()\n",
        "show_video()\n",
        "env.reset()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video alt=\"test\" autoplay \n",
              "                loop controls style=\"height: 400px;\">\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.03436611,  0.01016551, -0.02081133,  0.03576393])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg2wp6Duu7Ok"
      },
      "source": [
        "You can have a look of the tutorials and code prepared by [OpenAI](https://spinningup.openai.com/en/latest/user/introduction.html) for further details on RL."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWgV2gkTfpCc"
      },
      "source": [
        "# Coursework\n",
        "\n",
        "## Task 1: On-policy vs. Off-policy\n",
        "Use the code given below to run the training loop, where the agent is trained for 200 episodes. The agent we give follows a Q-learning approach, which is an off-policy approach. You will now change the approach to SARSA, which is an on-policy approach. Also, for both Q-learning and SARSA test two different policies: $\\epsilon$-greedy and Softmax. $\\epsilon$-greedy is already defined in the tutorial and implemented in the given agent. Softmax policy refers to sampling the next action following the probability distribution given by $Softmax(Q(s, a))$. We provide you the NumPy softmax function to normalize the Q-Values into a probability function to use before sampling. Similarly to RNN, in the softmax function, there is a temperature value involved, we set a default value that works, but you can tweak it if you find another value with better performance. Report the new value if you decide to do so.\n",
        "\n",
        "You will need to modify `act` and `replay` from the `DQNAgent` to implement the different approaches we ask for. Results may differ from run to run due to different initialization states. \n",
        "\n",
        "**Report**\n",
        "* Plot the average reward for the last 50 episodes vs. number of training episodes (train for 200 episodes) for the four agents trained: Q-learning and SARSA with both $\\epsilon$-greedy policy and Softmax policy. Attach in the Appendix the modifications done to `DQNAgent` to implement the different agents. Do not include your code, a simple explanation with the key modifications is enough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A47sXwdmhlrU"
      },
      "source": [
        "import random\n",
        "import gym\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.activations import softmax\n",
        "from keras.optimizers import Adam\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "def softmax(x, temperature=0.025): \n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    x = (x - np.expand_dims(np.max(x, 1), 1))\n",
        "    x = x/temperature    \n",
        "    e_x = np.exp(x)\n",
        "    return e_x / (np.expand_dims(e_x.sum(1), -1) + 1e-5)\n",
        "\n",
        "class DQNAgent:\n",
        "  def __init__(self, state_size, action_size):\n",
        "    self.state_size = state_size\n",
        "    self.action_size = action_size\n",
        "    self.memory = deque(maxlen=20000)\n",
        "    self.gamma = 0.95    # discount rate\n",
        "    self.epsilon = 1.0  # exploration rate\n",
        "    self.epsilon_min = 0.01\n",
        "    self.epsilon_decay = 0.995\n",
        "    self.learning_rate = 0.001\n",
        "    self.model = self._build_model()\n",
        "\n",
        "    \n",
        "  def _build_model(self):\n",
        "    # Neural Net for Deep-Q learning Model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
        "    model.add(Dense(48, activation='relu'))\n",
        "    model.add(Dense(self.action_size, activation='linear'))\n",
        "    model.compile(loss='mse',\n",
        "                  optimizer=Adam(lr=self.learning_rate))\n",
        "    return model\n",
        "\n",
        "  def remember(self, state, action, reward, next_state, done):\n",
        "    self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "  def act(self, state):\n",
        "    # We implement the epsilon-greedy policy\n",
        "    if np.random.rand() <= self.epsilon:\n",
        "        return random.randrange(self.action_size)\n",
        "    act_values = self.model.predict(state)\n",
        "    return np.argmax(act_values[0]) # returns action\n",
        "    \n",
        "    #softmax\n",
        "    # act_values = self.model.predict(state)\n",
        "    # act = softmax(act_values)[0]\n",
        "    # return np.random.choice(2,1, p=act)[0]\n",
        "\n",
        "\n",
        "  def exploit(self, state): # When we test the agent we dont want it to explore anymore, but to exploit what it has learnt\n",
        "    act_values = self.model.predict(state)\n",
        "    return np.argmax(act_values[0]) \n",
        "\n",
        "  def replay(self, batch_size):\n",
        "    minibatch = random.sample(self.memory, batch_size)\n",
        "    \n",
        "    state_b = np.squeeze(np.array(list(map(lambda x: x[0], minibatch))))\n",
        "    action_b = np.squeeze(np.array(list(map(lambda x: x[1], minibatch))))\n",
        "    reward_b = np.squeeze(np.array(list(map(lambda x: x[2], minibatch))))\n",
        "    next_state_b = np.squeeze(np.array(list(map(lambda x: x[3], minibatch))))\n",
        "    done_b = np.squeeze(np.array(list(map(lambda x: x[4], minibatch))))\n",
        "\n",
        "    ### Q-learning\n",
        "    # target = (reward_b + self.gamma * np.amax(self.model.predict(next_state_b), 1))\n",
        "    #SARSA\n",
        "    target = (reward_b + self.gamma * (self.model.predict(next_state_b)[:,self.act(next_state_b)]))\n",
        "    target[done_b==1] = reward_b[done_b==1]\n",
        "    target_f = self.model.predict(state_b)\n",
        "\n",
        "    for k in range(target_f.shape[0]):\n",
        "      target_f[k][action_b[k]] = target[k]\n",
        "    self.model.train_on_batch(state_b, target_f)\n",
        "    if self.epsilon > self.epsilon_min:\n",
        "        self.epsilon *= self.epsilon_decay\n",
        "\n",
        "  def load(self, name):\n",
        "    self.model.load_weights(name)\n",
        "  def save(self, name):\n",
        "    self.model.save_weights(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiW8Mr6VfvgM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567b46b6-7498-4441-8ce2-e1a1cf0824a7"
      },
      "source": [
        "  EPISODES = 200\n",
        "  env = gym.make('CartPole-v0')\n",
        "  state_size = env.observation_space.shape[0]\n",
        "  action_size = env.action_space.n\n",
        "  agent = DQNAgent(state_size, action_size)\n",
        "  batch_size = 32\n",
        "  episode_reward_list = deque(maxlen=50)\n",
        "  avg_re = []\n",
        "  for e in range(EPISODES):\n",
        "      state = env.reset()\n",
        "      state = np.reshape(state, [1, state_size])\n",
        "      total_reward = 0\n",
        "      for time in range(200):\n",
        "        action = agent.act(state)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        total_reward += reward\n",
        "        next_state = np.reshape(next_state, [1, state_size])\n",
        "        agent.remember(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "        if done:\n",
        "            break\n",
        "        if len(agent.memory) > batch_size:\n",
        "            agent.replay(batch_size)\n",
        "      episode_reward_list.append(total_reward)\n",
        "      episode_reward_avg = np.array(episode_reward_list).mean()\n",
        "      avg_re.append(episode_reward_avg)\n",
        "      print(\"episode: {}/{}, score: {}, e: {:.2}, last 50 ep. avg. rew.: {:.2f}\"\n",
        "                  .format(e, EPISODES, total_reward, agent.epsilon, episode_reward_avg))      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "episode: 0/200, score: 20.0, e: 1.0, last 50 ep. avg. rew.: 20.00\n",
            "episode: 1/200, score: 16.0, e: 0.99, last 50 ep. avg. rew.: 18.00\n",
            "episode: 2/200, score: 18.0, e: 0.9, last 50 ep. avg. rew.: 18.00\n",
            "episode: 3/200, score: 19.0, e: 0.83, last 50 ep. avg. rew.: 18.25\n",
            "episode: 4/200, score: 11.0, e: 0.79, last 50 ep. avg. rew.: 16.80\n",
            "episode: 5/200, score: 31.0, e: 0.68, last 50 ep. avg. rew.: 19.17\n",
            "episode: 6/200, score: 12.0, e: 0.64, last 50 ep. avg. rew.: 18.14\n",
            "episode: 7/200, score: 9.0, e: 0.61, last 50 ep. avg. rew.: 17.00\n",
            "episode: 8/200, score: 12.0, e: 0.58, last 50 ep. avg. rew.: 16.44\n",
            "episode: 9/200, score: 12.0, e: 0.55, last 50 ep. avg. rew.: 16.00\n",
            "episode: 10/200, score: 16.0, e: 0.51, last 50 ep. avg. rew.: 16.00\n",
            "episode: 11/200, score: 14.0, e: 0.48, last 50 ep. avg. rew.: 15.83\n",
            "episode: 12/200, score: 15.0, e: 0.45, last 50 ep. avg. rew.: 15.77\n",
            "episode: 13/200, score: 17.0, e: 0.41, last 50 ep. avg. rew.: 15.86\n",
            "episode: 14/200, score: 10.0, e: 0.39, last 50 ep. avg. rew.: 15.47\n",
            "episode: 15/200, score: 9.0, e: 0.38, last 50 ep. avg. rew.: 15.06\n",
            "episode: 16/200, score: 10.0, e: 0.36, last 50 ep. avg. rew.: 14.76\n",
            "episode: 17/200, score: 11.0, e: 0.34, last 50 ep. avg. rew.: 14.56\n",
            "episode: 18/200, score: 11.0, e: 0.33, last 50 ep. avg. rew.: 14.37\n",
            "episode: 19/200, score: 9.0, e: 0.31, last 50 ep. avg. rew.: 14.10\n",
            "episode: 20/200, score: 12.0, e: 0.3, last 50 ep. avg. rew.: 14.00\n",
            "episode: 21/200, score: 12.0, e: 0.28, last 50 ep. avg. rew.: 13.91\n",
            "episode: 22/200, score: 11.0, e: 0.27, last 50 ep. avg. rew.: 13.78\n",
            "episode: 23/200, score: 13.0, e: 0.25, last 50 ep. avg. rew.: 13.75\n",
            "episode: 24/200, score: 13.0, e: 0.24, last 50 ep. avg. rew.: 13.72\n",
            "episode: 25/200, score: 12.0, e: 0.22, last 50 ep. avg. rew.: 13.65\n",
            "episode: 26/200, score: 14.0, e: 0.21, last 50 ep. avg. rew.: 13.67\n",
            "episode: 27/200, score: 9.0, e: 0.2, last 50 ep. avg. rew.: 13.50\n",
            "episode: 28/200, score: 18.0, e: 0.19, last 50 ep. avg. rew.: 13.66\n",
            "episode: 29/200, score: 15.0, e: 0.17, last 50 ep. avg. rew.: 13.70\n",
            "episode: 30/200, score: 13.0, e: 0.16, last 50 ep. avg. rew.: 13.68\n",
            "episode: 31/200, score: 10.0, e: 0.16, last 50 ep. avg. rew.: 13.56\n",
            "episode: 32/200, score: 11.0, e: 0.15, last 50 ep. avg. rew.: 13.48\n",
            "episode: 33/200, score: 9.0, e: 0.14, last 50 ep. avg. rew.: 13.35\n",
            "episode: 34/200, score: 9.0, e: 0.14, last 50 ep. avg. rew.: 13.23\n",
            "episode: 35/200, score: 8.0, e: 0.13, last 50 ep. avg. rew.: 13.08\n",
            "episode: 36/200, score: 17.0, e: 0.12, last 50 ep. avg. rew.: 13.19\n",
            "episode: 37/200, score: 11.0, e: 0.12, last 50 ep. avg. rew.: 13.13\n",
            "episode: 38/200, score: 12.0, e: 0.11, last 50 ep. avg. rew.: 13.10\n",
            "episode: 39/200, score: 9.0, e: 0.11, last 50 ep. avg. rew.: 13.00\n",
            "episode: 40/200, score: 13.0, e: 0.099, last 50 ep. avg. rew.: 13.00\n",
            "episode: 41/200, score: 10.0, e: 0.095, last 50 ep. avg. rew.: 12.93\n",
            "episode: 42/200, score: 15.0, e: 0.088, last 50 ep. avg. rew.: 12.98\n",
            "episode: 43/200, score: 18.0, e: 0.081, last 50 ep. avg. rew.: 13.09\n",
            "episode: 44/200, score: 14.0, e: 0.076, last 50 ep. avg. rew.: 13.11\n",
            "episode: 45/200, score: 21.0, e: 0.069, last 50 ep. avg. rew.: 13.28\n",
            "episode: 46/200, score: 16.0, e: 0.064, last 50 ep. avg. rew.: 13.34\n",
            "episode: 47/200, score: 16.0, e: 0.059, last 50 ep. avg. rew.: 13.40\n",
            "episode: 48/200, score: 39.0, e: 0.049, last 50 ep. avg. rew.: 13.92\n",
            "episode: 49/200, score: 11.0, e: 0.047, last 50 ep. avg. rew.: 13.86\n",
            "episode: 50/200, score: 14.0, e: 0.044, last 50 ep. avg. rew.: 13.74\n",
            "episode: 51/200, score: 45.0, e: 0.035, last 50 ep. avg. rew.: 14.32\n",
            "episode: 52/200, score: 57.0, e: 0.026, last 50 ep. avg. rew.: 15.10\n",
            "episode: 53/200, score: 59.0, e: 0.02, last 50 ep. avg. rew.: 15.90\n",
            "episode: 54/200, score: 44.0, e: 0.016, last 50 ep. avg. rew.: 16.56\n",
            "episode: 55/200, score: 63.0, e: 0.012, last 50 ep. avg. rew.: 17.20\n",
            "episode: 56/200, score: 45.0, e: 0.01, last 50 ep. avg. rew.: 17.86\n",
            "episode: 57/200, score: 76.0, e: 0.01, last 50 ep. avg. rew.: 19.20\n",
            "episode: 58/200, score: 80.0, e: 0.01, last 50 ep. avg. rew.: 20.56\n",
            "episode: 59/200, score: 63.0, e: 0.01, last 50 ep. avg. rew.: 21.58\n",
            "episode: 60/200, score: 69.0, e: 0.01, last 50 ep. avg. rew.: 22.64\n",
            "episode: 61/200, score: 84.0, e: 0.01, last 50 ep. avg. rew.: 24.04\n",
            "episode: 62/200, score: 65.0, e: 0.01, last 50 ep. avg. rew.: 25.04\n",
            "episode: 63/200, score: 171.0, e: 0.01, last 50 ep. avg. rew.: 28.12\n",
            "episode: 64/200, score: 116.0, e: 0.01, last 50 ep. avg. rew.: 30.24\n",
            "episode: 65/200, score: 103.0, e: 0.01, last 50 ep. avg. rew.: 32.12\n",
            "episode: 66/200, score: 138.0, e: 0.01, last 50 ep. avg. rew.: 34.68\n",
            "episode: 67/200, score: 172.0, e: 0.01, last 50 ep. avg. rew.: 37.90\n",
            "episode: 68/200, score: 157.0, e: 0.01, last 50 ep. avg. rew.: 40.82\n",
            "episode: 69/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 44.64\n",
            "episode: 70/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 48.40\n",
            "episode: 71/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 52.16\n",
            "episode: 72/200, score: 183.0, e: 0.01, last 50 ep. avg. rew.: 55.60\n",
            "episode: 73/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 59.34\n",
            "episode: 74/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 63.08\n",
            "episode: 75/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 66.84\n",
            "episode: 76/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 70.56\n",
            "episode: 77/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 74.38\n",
            "episode: 78/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 78.02\n",
            "episode: 79/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 81.72\n",
            "episode: 80/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 85.46\n",
            "episode: 81/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 89.26\n",
            "episode: 82/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 93.04\n",
            "episode: 83/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 96.86\n",
            "episode: 84/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 100.68\n",
            "episode: 85/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 104.52\n",
            "episode: 86/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 108.18\n",
            "episode: 87/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 111.96\n",
            "episode: 88/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 115.72\n",
            "episode: 89/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 119.54\n",
            "episode: 90/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 123.28\n",
            "episode: 91/200, score: 185.0, e: 0.01, last 50 ep. avg. rew.: 126.78\n",
            "episode: 92/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 130.48\n",
            "episode: 93/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 134.12\n",
            "episode: 94/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 137.84\n",
            "episode: 95/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 141.42\n",
            "episode: 96/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 145.10\n",
            "episode: 97/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 148.78\n",
            "episode: 98/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 152.00\n",
            "episode: 99/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 155.78\n",
            "episode: 100/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 159.50\n",
            "episode: 101/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 162.60\n",
            "episode: 102/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 165.46\n",
            "episode: 103/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 168.28\n",
            "episode: 104/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 171.40\n",
            "episode: 105/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 174.14\n",
            "episode: 106/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 177.24\n",
            "episode: 107/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 179.72\n",
            "episode: 108/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 182.12\n",
            "episode: 109/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 184.86\n",
            "episode: 110/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 187.48\n",
            "episode: 111/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 189.80\n",
            "episode: 112/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 192.50\n",
            "episode: 113/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 193.08\n",
            "episode: 114/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 194.76\n",
            "episode: 115/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 196.70\n",
            "episode: 116/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 197.94\n",
            "episode: 117/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 198.50\n",
            "episode: 118/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.36\n",
            "episode: 119/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.36\n",
            "episode: 120/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.36\n",
            "episode: 121/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.36\n",
            "episode: 122/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.70\n",
            "episode: 123/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.70\n",
            "episode: 124/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.70\n",
            "episode: 125/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.70\n",
            "episode: 126/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.70\n",
            "episode: 127/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.70\n",
            "episode: 128/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.70\n",
            "episode: 129/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.70\n",
            "episode: 130/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.70\n",
            "episode: 131/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.70\n",
            "episode: 132/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.70\n",
            "episode: 133/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.70\n",
            "episode: 134/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.70\n",
            "episode: 135/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.70\n",
            "episode: 136/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.70\n",
            "episode: 137/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.70\n",
            "episode: 138/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.70\n",
            "episode: 139/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.70\n",
            "episode: 140/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.70\n",
            "episode: 141/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 200.00\n",
            "episode: 142/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 200.00\n",
            "episode: 143/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 200.00\n",
            "episode: 144/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 200.00\n",
            "episode: 145/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 200.00\n",
            "episode: 146/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 200.00\n",
            "episode: 147/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 200.00\n",
            "episode: 148/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 200.00\n",
            "episode: 149/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 200.00\n",
            "episode: 150/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 200.00\n",
            "episode: 151/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 200.00\n",
            "episode: 152/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 200.00\n",
            "episode: 153/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 200.00\n",
            "episode: 154/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 200.00\n",
            "episode: 155/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 200.00\n",
            "episode: 156/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 200.00\n",
            "episode: 157/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 200.00\n",
            "episode: 158/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 200.00\n",
            "episode: 159/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 200.00\n",
            "episode: 160/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 200.00\n",
            "episode: 161/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 200.00\n",
            "episode: 162/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 200.00\n",
            "episode: 163/200, score: 188.0, e: 0.01, last 50 ep. avg. rew.: 199.76\n",
            "episode: 164/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.76\n",
            "episode: 165/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.76\n",
            "episode: 166/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.76\n",
            "episode: 167/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.76\n",
            "episode: 168/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.76\n",
            "episode: 169/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.76\n",
            "episode: 170/200, score: 196.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 171/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 172/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 173/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 174/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 175/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 176/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 177/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 178/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 179/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 180/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 181/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 182/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 183/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 184/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 185/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 186/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 187/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 188/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 189/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 190/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 191/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 192/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 193/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 194/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 195/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 196/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 197/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 198/200, score: 200.0, e: 0.01, last 50 ep. avg. rew.: 199.68\n",
            "episode: 199/200, score: 194.0, e: 0.01, last 50 ep. avg. rew.: 199.56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGaDif7tDCom"
      },
      "source": [
        "# all = []\n",
        "all[2] = avg_re\n",
        "# all.append(avg_re)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "qZZbliBhDG3I",
        "outputId": "d859cc3f-f91a-4810-9040-d940c6e9a451"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(all[0],label=\"Q-ϵ-greedy\",c='C0')\n",
        "plt.plot(all[1],label=\"Q-softmax\",c='C1')\n",
        "plt.plot(all[2],label=\"SARSA-ϵ-greedy\",c='C2')\n",
        "plt.plot(all[3],label=\"SARSA-softmax\",c='C3')\n",
        "plt.title('Average reward vs. Number of training episodes')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.xlabel('Training episodes',fontsize=12)\n",
        "plt.ylabel('Average reward for the last 50 episodes',fontsize=12)\n",
        "plt.savefig(\"rl.png\",dpi=350)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}